\chapter{Conclusion}\label{chap:conclusion}

This thesis presents optimized algorithms for $k$-means++ initialization and Lloyd’s algorithm, specifically designed for one-dimensional (1D) clustering. By leveraging the structure of sorted data, the proposed methods replace the linear dependence on dataset size \(n\) with logarithmic factors, significantly improving computational efficiency while maintaining clustering quality. The optimized greedy $k$-means++ initialization achieves a time complexity of \(O(l \cdot k^2 \cdot \log n)\), while Lloyd’s algorithm iterations achieve \(O(i \cdot k \cdot \log n)\), where \(l\) is the number of local trials, and \(i\) the number of iterations. Additionally, the binary search-based algorithm for the two-cluster case deterministically converges to a Lloyd’s algorithm solution in \(O(\log n)\), bypassing iterative refinements entirely.

These methods offer significant benefits for latency-critical tasks and large-scale clustering problems. The practical relevance of these contributions is demonstrated in key applications such as quantization for large language models (LLMs), where the optimized algorithms achieve a 300-fold speedup over \texttt{scikit-learn}, as discussed in Section~\ref{sec:llm_quantization}. To ensure ease of use, a Python implementation of the proposed methods, optimized with just-in-time (JIT) compilation, is provided for practical deployment.

By exploiting the structure of 1D data, this thesis demonstrates that substantial computational improvements are achievable for $k$-means clustering, reducing dataset size dependencies from linear to logarithmic. These contributions address an important gap in the existing literature and deliver efficient, high-performance clustering tools ready for real-world applications.